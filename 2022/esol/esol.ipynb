{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(\n",
    "    lab=False,\n",
    "    line_length=79,\n",
    "    verbosity=\"DEBUG\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf87c9",
   "metadata": {},
   "source": [
    "# Predicting solubilities from molecular descriptors\n",
    "\n",
    "The supporting information to the article [ESOL: Estimating Aqueous Solubility Directly from Molecular Structure](https://pubs.acs.org/doi/10.1021/ci034243x) contains a data set with molecules (smiles) and their\n",
    "measured and predicted (by the ESOL model described in the article) aqueous solubilities. We can (down)load this data from [GitHub](https://github.com/dataprofessor)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3548408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data_file(url, output_file):\n",
    "    if pathlib.Path(output_file).is_file():\n",
    "        print(f\"File {output_file} exists - skipping download\")\n",
    "        return output_file\n",
    "    session = requests.Session()\n",
    "    session.headers.update(\n",
    "        {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:102.0) Gecko/20100101 Firefox/102.0\"\n",
    "        }\n",
    "    )\n",
    "    response = session.get(url, allow_redirects=True)\n",
    "    if response:\n",
    "        with open(output_file, \"w\") as output:\n",
    "            output.write(response.text)\n",
    "        print(f\"Downloaded file to: {output_file}\")\n",
    "        return output_file\n",
    "    else:\n",
    "        print(f\"Could not download file: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad924d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data_file(\n",
    "    \"https://raw.githubusercontent.com/dataprofessor/data/master/delaney.csv\",\n",
    "    \"esol.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"esol.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47845aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = data[\"Compound ID\"].values\n",
    "measured = data[\"measured log(solubility:mol/L)\"].values\n",
    "esol = data[\"ESOL predicted log(solubility:mol/L)\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51d0eb",
   "metadata": {},
   "source": [
    "## Having a quick look at the raw data\n",
    "\n",
    "First, we will plot the distributions of the measured and predicted solubilities and calculate the\n",
    "[coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) and the\n",
    "[mean absolute error](https://en.wikipedia.org/wiki/Root-mean-square_deviation#Mean_absolute_error)\n",
    "for the ESOL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb94f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "plt.style.use(\"seaborn-talk\")\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"talk\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cc045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scatterplot(ax, measured, predicted, model_name=None):\n",
    "    \"\"\"Add a measured vs. predicted scatter plot.\"\"\"\n",
    "    rsquared = r2_score(measured, predicted)\n",
    "    mae = mean_absolute_error(measured, predicted)\n",
    "    label = f\"R²: {rsquared:.2f}\\nMAE = {mae:.2f}\"\n",
    "    if model_name:\n",
    "        label = f\"{model_name}\\n{label}\"\n",
    "    ax.scatter(\n",
    "        measured,\n",
    "        predicted,\n",
    "        label=label,\n",
    "        alpha=0.8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    constrained_layout=True, ncols=2, figsize=(12, 5)\n",
    ")\n",
    "_, _, hist1 = ax1.hist(measured, density=True, alpha=0.5)\n",
    "_, _, hist2 = ax1.hist(esol, density=True, alpha=0.5)\n",
    "sns.kdeplot(\n",
    "    data=data,\n",
    "    x=\"measured log(solubility:mol/L)\",\n",
    "    ax=ax1,\n",
    "    label=\"Measured\",\n",
    "    color=hist1.patches[0].get_facecolor(),\n",
    "    lw=5,\n",
    ")\n",
    "sns.kdeplot(\n",
    "    data=data,\n",
    "    x=\"ESOL predicted log(solubility:mol/L)\",\n",
    "    ax=ax1,\n",
    "    label=\"ESOL\",\n",
    "    color=hist2.patches[0].get_facecolor(),\n",
    "    lw=5,\n",
    ")\n",
    "ax1.legend()\n",
    "ax1.set(xlabel=\"log (solubility)\", title=\"Distribution of solubilities\")\n",
    "\n",
    "ax2.scatter([], [])  # cycle colors\n",
    "add_scatterplot(ax2, measured, esol)\n",
    "ax2.set(\n",
    "    xlabel=\"Measured log (solubility)\",\n",
    "    ylabel=\"Predicted (ESOL)\",\n",
    "    title=\"Measured vs. predicted\",\n",
    ")\n",
    "ax2.legend()\n",
    "sns.despine(fig=fig, offset=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb6d4d",
   "metadata": {},
   "source": [
    "That looks reasonable. The model overestimates the solubility between −4.2 and −1.2 −4.2 to −1.2 and\n",
    "underestimates for < −5 and > 0.\n",
    "\n",
    "We can also have a look at the molecules in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b1edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # add a progress bar\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import (\n",
    "    AllChem,\n",
    "    Draw,\n",
    "    rdCoordGen,\n",
    ")\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from IPython.display import SVG\n",
    "\n",
    "IPythonConsole.ipython_useSVG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_molecules_from_smiles(smiles):\n",
    "    molecules = []\n",
    "    for smilei in tqdm(smiles):\n",
    "        mol = Chem.MolFromSmiles(smilei)\n",
    "        rdCoordGen.AddCoords(mol)\n",
    "        molecules.append(mol)\n",
    "    return molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26896adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = make_molecules_from_smiles(data[\"SMILES\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ebd3a",
   "metadata": {},
   "source": [
    "Let us show the molecules with the highest and lowest solubility: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb83491",
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = []\n",
    "legends = []\n",
    "idx_max, idx_min = np.argmax(measured), np.argmin(measured)\n",
    "for i in (idx_max, idx_min):\n",
    "    mols.append(molecules[i])\n",
    "    legends.append(f\"{names[i]}\\nlog solubility = {measured[i]:.3g}\")\n",
    "\n",
    "drawing = Draw.rdMolDraw2D.MolDraw2DSVG(600, 280, 300, 280)\n",
    "options = drawing.drawOptions()\n",
    "options.drawMolsSameScale = False\n",
    "options.fixedBondLength = 50\n",
    "options.legendFraction = 0.25\n",
    "drawing.DrawMolecules(mols, legends=legends)\n",
    "drawing.FinishDrawing()\n",
    "SVG(drawing.GetDrawingText())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1153d04",
   "metadata": {},
   "source": [
    "And the 6 molecules with the largest relative errors.\n",
    "The (logarithmic) solubilities can be zero, so here I will use a\n",
    "variant of the [relative difference](https://en.wikipedia.org/wiki/Relative_change_and_difference):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81782871",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = abs(measured - esol) / (0.5 * (abs(measured) + abs(esol)))\n",
    "idx = np.argsort(error)[-6:]\n",
    "\n",
    "mols = []\n",
    "legends = []\n",
    "for i in idx:\n",
    "    mols.append(molecules[i])\n",
    "    legends.append(\n",
    "        f\"{names[i]}\\nSolubility = {measured[i]:.2g}\\nESOL: {esol[i]:.2g}\"\n",
    "    )\n",
    "\n",
    "drawing = Draw.rdMolDraw2D.MolDraw2DSVG(1000, 600, 300, 300)\n",
    "options = drawing.drawOptions()\n",
    "options.drawMolsSameScale = False\n",
    "options.fixedBondLength = 30\n",
    "options.legendFraction = 0.25\n",
    "drawing.DrawMolecules(mols, legends=legends)\n",
    "drawing.FinishDrawing()\n",
    "SVG(drawing.GetDrawingText())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f7d0fc",
   "metadata": {},
   "source": [
    "## Calculating molecular descriptors\n",
    "\n",
    "For creating a predictive model, we need some variables. I will here just calculate [all molecular\n",
    "descriptors available in RDKit](https://www.rdkit.org/docs/GettingStartedInPython.html#list-of-available-descriptors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92100c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Descriptors, Descriptors3D\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90101d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rdkit_descriptors(molecules):\n",
    "    \"\"\"Calculate rdkit 2D-descriptors for a set of molecules.\"\"\"\n",
    "    descriptors = [i[0] for i in Descriptors._descList]\n",
    "    calculator = MoleculeDescriptors.MolecularDescriptorCalculator(descriptors)\n",
    "    values = [calculator.CalcDescriptors(mol) for mol in tqdm(molecules)]\n",
    "    values = np.array(values)\n",
    "    data = pd.DataFrame(values, columns=descriptors)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b67006",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdkit_descriptors = calculate_rdkit_descriptors(molecules)\n",
    "rdkit_descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1ff3fc",
   "metadata": {},
   "source": [
    "Let us do some preprocessing here:\n",
    "\n",
    "1. Remove columns with nan/inf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_before = set(list(rdkit_descriptors.columns))\n",
    "rdkit_descriptors = rdkit_descriptors.apply(\n",
    "    pd.to_numeric, errors=\"coerce\", axis=1\n",
    ")\n",
    "rdkit_descriptors = rdkit_descriptors.replace([np.inf, -np.inf], np.nan)\n",
    "rdkit_descriptors = rdkit_descriptors.dropna(axis=1)\n",
    "columns_after = set(list(rdkit_descriptors.columns))\n",
    "diff = columns_before - columns_after\n",
    "if len(diff) > 0:\n",
    "    print(\"Removed:\", list(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3ae50",
   "metadata": {},
   "source": [
    "2. Remove variables with low variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "columns_before = set(list(rdkit_descriptors.columns))\n",
    "threshold = VarianceThreshold()\n",
    "threshold.fit(rdkit_descriptors)\n",
    "columns_after = list(threshold.get_feature_names_out())\n",
    "diff = columns_before - set(columns_after)\n",
    "rdkit_descriptors = rdkit_descriptors[columns_after]\n",
    "if len(diff) > 0:\n",
    "    print(\"Removed:\", list(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1b6e2",
   "metadata": {},
   "source": [
    "3. Remove highly correlated columns. Some of the descriptors are essentially\n",
    "   measuring the same thing, for instance, the different molecular weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdkit_descriptors[[\"MolWt\", \"HeavyAtomMolWt\", \"ExactMolWt\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a536e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = rdkit_descriptors.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.975)]\n",
    "if len(to_drop) > 0:\n",
    "    print(\"Removed:\", to_drop)\n",
    "    rdkit_descriptors.drop(labels=to_drop, axis=1, inplace=True)\n",
    "rdkit_descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9020e4ca",
   "metadata": {},
   "source": [
    "## Creating a predictive model\n",
    "\n",
    "We now have some variables and can create a predictive model. For this, I will use [CatBoost](https://catboost.ai/) - it usually gives good results without too much parameter tuning. One could also use [XGBoost](https://xgboost.readthedocs.io/en/stable/), [LightGBM](https://lightgbm.readthedocs.io/), or linear models such as [LASSO](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) or [Elastic net](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2669801",
   "metadata": {},
   "source": [
    "### Creating the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ca0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33558beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = data[\"measured log(solubility:mol/L)\"].to_numpy().reshape(-1, 1)\n",
    "variables = rdkit_descriptors.columns  # Just select all variables\n",
    "X_raw = rdkit_descriptors[variables].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_scale(X_raw, y_raw):\n",
    "    \"\"\"Split into training and test sets and scale.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_raw,\n",
    "        y_raw,\n",
    "        test_size=0.33,\n",
    "        random_state=5,\n",
    "    )\n",
    "\n",
    "    scale_x = StandardScaler()\n",
    "    scale_y = StandardScaler()\n",
    "    scale_x.fit(X_train)\n",
    "    scale_y.fit(y_train)\n",
    "\n",
    "    X_train = scale_x.transform(X_train)\n",
    "    X_test = scale_x.transform(X_test)\n",
    "\n",
    "    y_train = scale_y.transform(y_train)\n",
    "    y_test = scale_y.transform(y_test)\n",
    "    return X_train, X_test, y_train, y_test, scale_x, scale_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scale_x, scale_y = split_and_scale(\n",
    "    X_raw, y_raw\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7672f5f5",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "I said above that [CatBoost](https://catboost.ai/) usually gives good results without too much parameter tuning.\n",
    "So I will do no parameter tuning here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b858de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = cb.CatBoostRegressor(verbose=False)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb44851",
   "metadata": {},
   "source": [
    "### Assessing the model\n",
    "To assess the model, I will plot the predicted and measured solubilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_train_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Plot measured vs. predicted for test and train.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        constrained_layout=True, ncols=2, figsize=(12, 5)\n",
    "    )\n",
    "    # Training:\n",
    "    add_scatterplot(ax1, y_train, model.predict(X_train))\n",
    "    ax1.set(xlabel=\"measured\", ylabel=\"predicted\", title=\"Training set\")\n",
    "    ax1.legend()\n",
    "    # Testing:\n",
    "    add_scatterplot(ax2, y_test, model.predict(X_test))\n",
    "    ax2.set(xlabel=\"measured\", ylabel=\"predicted\", title=\"Test set\")\n",
    "    ax2.legend()\n",
    "    sns.despine(fig=fig, offset=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_train_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af35b62",
   "metadata": {},
   "source": [
    "That looks promising (**Note:** the `MAE` is here calculated for the scaled data).\n",
    "\n",
    "Let us compare with the measured solubilities and the ESOL predicted solubilities.\n",
    "For the comparison, I transform the output from the model back to solubilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scale_x.transform(X_raw)\n",
    "y_pred = model.predict(X)\n",
    "model_predict = scale_y.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "models_table = {\n",
    "    \"Measured\": measured,\n",
    "    \"ESOL\": esol,\n",
    "    \"CatBoost\": model_predict,\n",
    "}\n",
    "models_table = pd.DataFrame(models_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    constrained_layout=True, ncols=2, figsize=(12, 5)\n",
    ")\n",
    "ax2.scatter([], [])  # Just to cycle colors\n",
    "for key in models_table:\n",
    "    sns.kdeplot(\n",
    "        data=models_table,\n",
    "        x=key,\n",
    "        ax=ax1,\n",
    "        label=key,\n",
    "        lw=5,\n",
    "    )\n",
    "    if key != \"Measured\":\n",
    "        add_scatterplot(\n",
    "            ax2, models_table[\"Measured\"], models_table[key], model_name=key\n",
    "        )\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set(xlabel=\"Solubility\", title=\"Distribution of solubilities\")\n",
    "ax2.set(\n",
    "    xlabel=\"Measured solubility\",\n",
    "    ylabel=\"Predicted solubility\",\n",
    "    title=\"Measured vs. predicted\",\n",
    ")\n",
    "ax2.legend()\n",
    "sns.despine(fig=fig, offset=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd872a3",
   "metadata": {},
   "source": [
    "The model seems to improve the over/underestimation in ESOL.\n",
    "But the new model uses **many** variables. Let us inspect it to see\n",
    "if we can simplify it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf0a81",
   "metadata": {},
   "source": [
    "### Inspecting the model and creating a simplified model\n",
    "To simplify the model, I aim to create a linear model with few (say 4) features. To select these features I\n",
    "inspect their [importance](https://catboost.ai/en/docs/concepts/fstr#regular-feature-importance) and\n",
    "[shap values](https://shap.readthedocs.io/en/latest/index.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef914912",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.get_feature_importance()\n",
    "idx = np.argsort(feature_importance)\n",
    "pos = np.arange(len(idx))\n",
    "\n",
    "# Just show the 10 most important:\n",
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(8, 6))\n",
    "ax.set_yticks(pos)\n",
    "ax.set_yticklabels(variables[idx])\n",
    "ax.barh(pos[-10:], feature_importance[idx[-10:]])\n",
    "ax.set(xlabel=\"Feature importance\")\n",
    "sns.despine(fig=fig, offset=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model, feature_names=variables)\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    features=X,\n",
    "    show=False,\n",
    "    max_display=10,\n",
    ")\n",
    "cbar = fig.axes[-1]\n",
    "cbar.set_aspect(\"auto\")\n",
    "fig.tight_layout()\n",
    "cbar.set_box_aspect(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266161d",
   "metadata": {},
   "source": [
    "Here we see, for instance, that a higher `MolLogP` has a negative\n",
    "impact on solubility and that a lower molecular weight (`MolWt`)\n",
    "has a positive impact. This is probably what you could have guessed before\n",
    "making the model. Here is a closer inspection of the molecule with the highest solubility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[idx_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51778e",
   "metadata": {},
   "source": [
    "and for the lowest solubility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d6bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[idx_min])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2914aa8",
   "metadata": {},
   "source": [
    "We see here that `MolLogP` has a positive impact on the prediction for the molecule with highest solubility, and a negative impact for the molecule with the lowest solubility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376f8c1",
   "metadata": {},
   "source": [
    "OK, so we have an idea of the most important variables. Let pick 4 simple ones (from the first plot\n",
    "of the feature importance) and make a linear model,\n",
    "for instance:\n",
    "\n",
    "1. `MolLogP` (Wildman-Crippen LogP value.)\n",
    "2. `MolWt` (The molecular weight.)\n",
    "3. `MinPartialCharge` (Smallest [Gasteiger](https://doi.org/10.1016/0040-4020(80)80168-2) partial charge.)\n",
    "4. `NOCount` (Number of Nitrogens and Oxygens.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f013779",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables2 = [\n",
    "    \"MolLogP\",\n",
    "    \"MolWt\",\n",
    "    \"MinPartialCharge\",\n",
    "    \"NOCount\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7493287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw2 = rdkit_descriptors[variables2].to_numpy()\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2, scale_x2, scale_y2 = split_and_scale(\n",
    "    X_raw2, y_raw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ff9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73248941",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    \"alpha\": np.logspace(-3, 0, 20),\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    Lasso(fit_intercept=False, max_iter=10000),\n",
    "    parameters,\n",
    "    cv=10,\n",
    ")\n",
    "grid.fit(X_train2, y_train2)\n",
    "model2 = grid.best_estimator_\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_train_model(model2, X_train2, y_train2, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ce73c",
   "metadata": {},
   "source": [
    "The simplified model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d551b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math\n",
    "\n",
    "terms = [\n",
    "    f\"{i:.2g}×(\\\\text{{{var}}})\" for i, var in zip(model2.coef_, variables2)\n",
    "]\n",
    "equation = \"y =\" + \"\".join(terms)\n",
    "display(Math(equation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d9345",
   "metadata": {},
   "source": [
    "This simplified model has a performance similar to the ESOL model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
